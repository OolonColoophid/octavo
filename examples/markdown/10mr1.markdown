---
title: "MPSMD2RES Workshop 10: Multiple Regression (1)"
title-meta: "MPSMD2RES Workshop 10: Multiple Regression (1)"
author: "Dr Ian Hocking, Psychology Programme"
date: "September 2016 to April 2017"
version: 1.2
headimage: "$HOME/Dropbox/CCCU/text/deploy/media/2res/tufteHeadImageCompass"
headquote: "Research is creating new knowledge."
headquoteauthor: "Neil Armstrong"
httpdestination: "http://cccupsychology.com/deployIh/2res/workshops/"
remotedirectory: "2res/workshops/"
deployto: "$HOME/Dropbox/CCCU/text/2res/deploy/workshops"
formats: "all"
preview: ""
ftpdeploy: "yes"
spokendeploy: "yes"
refreshcalendar: "no"
customfilterone: "pandoc-csv2table"
customfiltertwo: "pandoc-crossref"
customfilterthree: "pandoc-citeproc"
papersize: A4
toc-depth: 1
toc: 1
colorlinks: 1
boxlinks: true
linespread: "1.3"
numbersections: "yes"
bibliography: "$HOME/Dropbox/CCCU/text/biblio/handbooks/2RES.bib"
citation-style: "https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl"
link-citations: false
mdfivehashset: "yes"
redact: "no"
tblPrefix: "Table"
eqnPrefix: "Equation"
figPrefix: "Figure"
autoEqnLabels: true
...

# Overview

-----------------------  -------------------------------------
*Data files required*    [Health](https://www.dropbox.com/s/ktcu0rcm799ke9a/10mr1Health.sav?dl=0)

*Booklet Version*        & version &

*Format*                 & documentFormat &

-----------------------  -------------------------------------

# Objectives

This workshop booklet will take you through a single example of multiple regression. You will learn how to set up and run the regression, interpret each aspect of the output, and make an overall summary of the model.

&& 2resWorkshopBookletHeader

# Workshop

<div latex="true" class="answer" id="Answer"> 

All SPSS data files and syntax:

[Health data](https://www.dropbox.com/s/ktcu0rcm799ke9a/10mr1Health.sav?dl=0)

[Health syntax](https://www.dropbox.com/s/3h370jftefrreid/10mr1Health.sps?dl=0)

</div>

In this workshop, we're going to run two multiple regression analyses on the same set of data, which contain health information about selected American cities. In the file, each city is a row. The variables provide information about certain health statistics, which you can see in [@tbl:Health].

-----------------------  -------------------------------------------------
*Measure*                *Description*
-----------------------  -------------------------------------------------
deathRate                Death rate per 10000 residents

doctorAvailabiltiy       Doctor availability per 100,000 residents

hospitalAvailability     Hospital availability per 100,000 residents

annualIcnome             Annual per capita income in thousands of dollars

populationDesnity        Population density people per square mile

-----------------------  -------------------------------------------------

Table: Measures and descriptions for the American city health data {#tbl:Health}

The scenario:

> Imagine that you are a US government researcher tasked with predicting the availability of doctors based on the other health data you have (i.e. the other variables in [@tbl:Health]). You're interested in developing a model that can be applied to other cities where the doctor availability is unknown, but where the other variables are known. 

We'll now run a multiple regression in which we try to predict the availability of a doctor from the other variables. Thus, the *outcome* variable (or dependent variable) will be availability of a doctor. The *predictor* variables (or independent variables) will be the remaining variables.

Read through the instructions below before carrying out your multiple regression.

<div latex="true" class="highlight" id="Remember">

On this occasion, we will not examine whether the data fit the assumptions of multiple regression. This should keep things simpler for your first attempt. Assumptions, however, are very important, and we'll be looking at them again in the next booklet.

</div>

## Step One: Set up the Linear Regression

<div latex="true" class="task" id="Task">

(@) Download [Health data](https://www.dropbox.com/s/ktcu0rcm799ke9a/10mr1Health.sav?dl=0) and familiarise yourself with the data by running *Descriptives*.

</div>

<div latex="true" class="answer" id="Answer">

We have a range of variables here with different characteristics. Per capita income seems quite low (range 7.2k to 13k), but bear in mind these data are historical.

---

SPSS syntax for the above:

~~~

DESCRIPTIVES VARIABLES=deathRate doctorAvailability 
hospitalAvailability annualIncome 
    populationDensity
  /STATISTICS=MEAN STDDEV MIN MAX.

~~~

</div>

<div latex="true" class="task" id="Task">

(@) Go to *Analyze > Regression > Linear...* and enter 'doctorAvailability' as your dependent variable (i.e. the one you wish to predict) and all the other variables into the *Inpependent(s)* box, as you see in [@fig:SPSSreg].

</div>

![SPSS Linear Regression Dialogue](.10mr1/25-11-2016-76250.png "SPSS Linear Regression Dialogue"){#fig:SPSSreg}

<div latex="true" class="task" id="Task">

(@) Select the correct statistics. We want *Estimates*, *Confidence interals*, the *Model fit*, *Descriptives*, and *Part and partial correlations*. See [@fig:SPSSregStat].

</div>

![SPSS Linear Regression Statistics](.10mr1/25-11-2016-14448.png "SPSS Linear Regression Statistics"){#fig:SPSSregStat}

In this simple case, that's as much as we need to tell SPSS.

<div latex="true" class="task" id="Task">

(@) Go ahead and run the multiple regression using the steps above.

</div>


<div latex="true" class="answer" id="Answer">

SPSS syntax:

~~~

* Regression.
REGRESSION
  /DESCRIPTIVES MEAN STDDEV CORR SIG N
  /MISSING LISTWISE
  /STATISTICS COEFF OUTS CI(95) R ANOVA ZPP
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT doctorAvailability
  /METHOD=ENTER deathRate hospitalAvailability 
  annualIncome populationDensity.

~~~


</div>

## Step 2: Interpret the Output

SPSS should now have produced:

- *Descriptive statistics*, which should be the same as your original descriptive statistics. Use this table to check that your data have been entered into the regression correctly.

- *Correlations*, which show you the correlation[^pearson] between the variables. As we shall see, correlations among your predictor variables can be problematic for the regression model.

[^pearson]:Pearson product moment correlation. 

- *Variables Entered/Removed*, which tells you the variables that have been used. It is possible to remove variables. If you've requested this, it will be reported here.

- *Model Summary*, which tells about the fit of the regression model.

- *ANOVA*, which gives you a sense of whether your model is better than a random one.

- *Coefficients*, from which you can build a complete picture of your regression equation.

Let's go through each of these. We'll skip *Descriptives*.

<div latex="true" class="journal" id="Journal">

(@) What do you notice about the *Correlations* matrix, excerpted in [@fig:regCorrelations]?

- Don't be confused by the table. The row labelled *Pearson Correlation* shows the correlations. The second row, labelled *Sig. (1-tailed)*, shows the *p* value of each corresponding *r* from the row above.

</div>

![SPSS Output---Correlations, excerpt](.10mr1/25-11-2016-95490.png "SPSS Output---Correlations, excerpt"){#fig:regCorrelations}

<div latex="true" class="answer" id="Answer">

Many of the correlations are not significant, but the availability of doctors is correlated with annual income (*r* = .43, *p* < .05) and with hospital availability (*r* = .27, *p* < .05).

</div>

Look at the *Model Summary*, [@fig:regSummary].

![SPSS Output---Model Summary](.10mr1/25-11-2016-50159.png "SPSS Output---Model Summary"){#fig:regSummary}

<div latex="true" class="journal" id="Journal">

(@) Report *Multiple R*, $R^2$, and $R^2_{adj}$. 

(@) Include a plain English description of what each measure is telling you.

</div>

<div latex="true" class="answer" id="Answer">

- *R* = .55. This shows that the overall relationship between the dependent variable (doctor availability) and the independent variables is moderate.

- $R^2$ = .30. The independent variables account for 30% of the variability in doctor availability data (unadjusted for the number of independent variables---that is, predictors---and based solely on our sample characteristics).

- $R^2_{adj}$ = .24. The independent variables account for 30% of the variability in doctor availability data (*adjusted* for the number of independent variables---that is, predictors---and based on an estimate of the population characteristics).

</div>

Now look at the *ANOVA* table, [@fig:regAnova].

![SPSS Output---ANOVA](.10mr1/25-11-2016-49796.png "SPSS Output---ANOVA"){#fig:regAnova}

<div latex="true" class="journal" id="Journal">

(@) Report *F* in the standard way.

(@) In plain English, what is this *F* ratio telling you?

</div>

<div latex="true" class="answer" id="Answer">

- *F* (4, 48) = 5.19, *MSE* = 1085.42, *p* < .05.

- This tells us that our regression model (a multidimensional plane, in this case, because each new variable adds a new dimension) fits the variability in the dependent variable (doctor availability) better than a 'null' model where we use the mean of the dependent variable. On this basis, because the *F* ratio is significant, we can consider our overall model to be reliable.

</div>

We'll now look at the table of *Coefficients*, [@fig:regCoeff]. Because its text might be too small, I've broken it down into two figures, [@fig:regCoeffB] and [@fig:regCoeffTciCor]. These show:

- *Unstandardized coefficients*, which tell us the strength and direction of the relationship of each predictor with the dependent variable.

- *Standardised coefficients*, which tell us the strength and direction of each predictor-dependent variable relationship *on a standard scale* (the Z distribution). Furthermore, because these values are standardised, they can be meaningfully compared (whereas the unstandardized coefficients cannot, because they are expressed in units of the dependent variable).

- *t (with associated significance)*, which tells us whether slope of the unstandardised coefficient (above) is different from 0. If it's not significant, the predictor is no better than chance at predicting variability in the dependent variable.

- *95% confidence interval for B*, which gives us the lower and upper bounds of a range within which each unstandardised coefficient should fall on 95% of occasions if were to keep sampling forever.

- *Correlations*, which tell us (1) zero order, (2) partial and (3) part correlations. Remember that (1) is a simple correlation between the dependent variable and a given independent variable; (2) is the correlation between the DV and an IV when the variance explained by all other IVs has been removed from both the IV and DV; (3) is (in shared variance terms) the amount of variance in the DV uniquely explained by the IV.

![SPSS Output---Coefficients Overall](.10mr1/25-11-2016-906.png "SPSS Output---Coefficients Overall"){#fig:regCoeff}

![SPSS Output---Coefficients, Bs and Betas](.10mr1/25-11-2016-86199.png "SPSS Output---Coefficients, Bs and Betas"){#fig:regCoeffB}

![SPSS Output---Coefficients, Ts, CIs and Correlations](.10mr1/25-11-2016-7569.png "SPSS Output---Coefficients, Ts, CIs and Correlations"){#fig:regCoeffTciCor}

<div latex="true" class="journal" id="Journal">

(@) Which of the predictors are reliable?

</div>

<div latex="true" class="answer" id="Answer">

Only hospital availability (*t* = 2.29, *p* < .05) and annual income (*t* = 3.75, *p* < .05) are significant predictors.

</div>

<div latex="true" class="journal" id="Journal">

(@) State the unstandardised regression equation.

</div>

<div latex="true" class="answer" id="Answer">

$doctor\ availability=-77.12+3.13(death\ rate)+0.03(hospital\ availability)+16.25(annual\ income)-0.08(population)$

</div>

<div latex="true" class="journal" id="Journal">

(@) State the standardised regression equation.

</div>

<div latex="true" class="answer" id="Answer">

$Zdoctor\ availability=0.14(Zdeath\ rate)+0.29(Zhospital\ availability)+0.46(Zannual\ income)-0.09(Zpopulation)$

</div>

<div latex="true" class="journal" id="Journal">

(@) What do you notice about difference in ranked standardised versus unstandardised coefficients?

</div>

<div latex="true" class="answer" id="Answer">

- In terms of unstandardised coefficients, the order (greatest first) is annual income, death rate, hospital availability and population density. When these are standardised, the order changes to annual income, hospital availability, death rate, and population density.

- So death rate and hospital availability have swapped. While death rate might appear to have a stronger relationship with doctor availability than hospital availability (from the perspective of the unstandardised coefficients, which are not fully comparable), the standardised model suggests that hospital availability has the stronger relationship. 

</div>

<div latex="true" class="journal" id="Journal">

(@) Which variable uniquely explains the most variability in doctor availability, and why?

</div>

<div latex="true" class="answer" id="Answer">

Annual per capita income. Because its *part* correlation is .452. We can square this value to get a measure of unique variability, which is 20.43%. 

</div>

<div latex="true" class="journal" id="Journal">

(@) Summarise the findings.

</div>

<div latex="true" class="answer" id="Answer">

The association between the dependent and predictor variables was moderate (Multiple R = .55). Overall, the model was significant, *F* (4,48) = 5.19, *MSE* = 1085.42, *p* < .05. Together, death rate, hospital availability, annual income and population density accounted for 30.2% of variation in doctor availability (adjusted R-square = 24.4%). Only hospital availability (*t* = 2.29, *p* < .05) and annual income (*t* = 3.75, *p* < .05) were significant predictors. The unstandardised regression coefficient for hospital availability was .03 (95% CI [.00, .06]), while the unstandardised coefficient for annual income was 16.25 (95% CI [7.54, 24.96]. The standardised coefficients were .29 and .46 respectively. Annual income explained more unique variance in doctor availability (20.43%) than did hospital availability (7.61%).

</div>

# Versions {#versions}

& deployments &

&& licence

