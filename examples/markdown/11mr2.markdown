---
title: "MPSMD2RES Workshop 11: Multiple Regression (2)"
title-meta: "MPSMD2RES Workshop 11: Multiple Regression (2)"
author: "Dr Ian Hocking, Psychology Programme"
date: "September 2016 to April 2017"
version: 1.2
headimage: "$HOME/Dropbox/CCCU/text/deploy/media/2res/tufteHeadImageCompass"
headquote: "Research is creating new knowledge."
headquoteauthor: "Neil Armstrong"
httpdestination: "http://cccupsychology.com/deployIh/2res/workshops/"
remotedirectory: "2res/workshops/"
deployto: "$HOME/Dropbox/CCCU/text/2res/deploy/workshops"
formats: "octavoTuftePdf, octavoNormalPdf, octavoOpenDyslexic, octavoLargePdf, octavoSpoken"
preview: ""
ftpdeploy: "yes"
spokendeploy: "yes"
refreshcalendar: "no"
customfilterone: "pandoc-csv2table"
customfiltertwo: "pandoc-crossref"
customfilterthree: "pandoc-citeproc"
papersize: A4
toc-depth: 1
toc: 1
colorlinks: 1
boxlinks: true
linespread: "1.3"
numbersections: "yes"
bibliography: "$HOME/Dropbox/CCCU/text/biblio/handbooks/2RES.bib"
citation-style: "https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl"
link-citations: false
solariseddarkon: false 
solariseddarkoff: true
mdfivehashset: "yes"
redact: "yes"
tblPrefix: "Table"
eqnPrefix: "Equation"
figPrefix: "Figure"
autoEqnLabels: true
...

# MPSMD2RES Workshop 11: Multiple Regression (2)

# Overview

-----------------------  -------------------------------------
*Data files required*    [Worry](https://www.dropbox.com/s/03ntm6g2tlmrn6y/11mr2Worry.sav?dl=0)

*Booklet Version*        & version &

*Format*                 & documentFormat &

-----------------------  -------------------------------------

# Objectives

This workshop booklet will take you through a second multiple regression, including the testing of assumptions.

&& 2resWorkshopBookletHeader

# Workshop

<div latex="true" class="answer" id="Answer"> 

All SPSS data files and syntax:

[Worry data](https://www.dropbox.com/s/03ntm6g2tlmrn6y/11mr2Worry.sav?dl=0)

[Worry syntax](https://www.dropbox.com/s/5t0wlgx7ppvunhw/11mr2Worry.sps?dl=0)

</div>

Here is the scenario:

> The researcher is interested in finding out the extent to which worry and conscientiousness predict a person’s time management behaviour, the theory being that people who are highly conscientious and worry more will be more likely to engage in time-management behaviours.

This datafile comes from 100 respondents who filled out a questionnaire that contained measures of Worry (16 items), Conscientiousness (16 items), and Time Management Behaviour (34 items). Notice that there are columns to represent where an item has been reverse-scored and that at the very end of the datafile you have three ‘total’ columns that have each respondents’ total scores in them.



## Step One: Data overview

<div latex="true" class="task" id="Task">

(@) Download the [Worry data](https://www.dropbox.com/s/03ntm6g2tlmrn6y/11mr2Worry.sav?dl=0) and familiarise yourself with it by running *Descriptives*.

</div>

<div latex="true" class="answer" id="Answer">

There's much we could look at here. In terms of the three total variables, we have conscientiousness (mean = 46.16, standard deviation = 10.00), time management behaviour (mean = 103.79, standard deviation = 18.44) and worry (mean = 50.20, 11.89).

---

SPSS syntax for the above:

~~~

DESCRIPTIVES VARIABLES=consTotal worryTotal tmbTotal
  /STATISTICS=MEAN STDDEV MIN MAX.

~~~

</div>

## Step Two: Choose your method for entering predictors into the model

For this project you will use *Forced Entry*, in which all the predictors are entered at the same time. This method tells us how much variance in the outcome can be explained by the whole model (all predictors together) and how much variance in the outcome can be *uniquely* explained by each individual predictor. The alternative would be to enter, or remove, them one at a time based on some kind of criterion [@field2009discovering].

## Step Three: Set up the multiple regression

Before you go ahead and run the regression, read through the next steps so that you can get a sense of them.

<div latex="true" class="task" id="Task">

(@) Go to *Analyze* > *Regression* > *Linear* and enter the variable you wish to predict as the *Dependent*, and the variables you are using to predict it as the *Independents*. Your dialogue box should look like [@fig:mr2Box].

- Make sure that the *Method:* box reads *Enter*.

</div>

![SPSS Multiple Regression dialogue](.11mr2/01-12-2016-47993.png "SPSS Multiple Regression dialogue"){#fig:mr2Box}

## Step Four: Checking assumptions of multiple regression

Last time, you carried out the multiple regression without checking for assumptions. But, like any statistical test, multiple regression has certain prerequisites. The analysis will become unreliable if these are not observed.

<div latex="true" class="task" id="Task">

(@) Test for *normality*, *homoscedasticity* and *linearity* by clicking on *Plots*. 

- In *Standardized Residual Plots*, select both *Histogram* and *Normal Probability Plot*. 

- In the *Scatter 1 of 1* option, select *\*ZRESID* from the left hand box and move it into the *Y:* box; select *\*ZPRED* and move it into the *X:* box. This will produce a scatterplot of the standardised residuals (\*ZRESID) against the standardised predicted outcome (\*ZPRED).

- Your settings should look like the [@fig:mr2Linear].

</div>

![SPSS Linear Regression, Plots](.11mr2/01-12-2016-72248.png "SPSS Linear Regression, Plots"){#fig:mr2Linear}

<div latex="true" class="task" id="Task">

(@) Test for the assumption of *independent errors* by producing the Durbin-Watson statistic. You'll find this in the *Statistics* box, [@fig:mr2Stats].

- Include the other checkboxes you see in [@fig:mr2Stats]: *Estimates*, *Model fit*, *Descriptives*, *Part and partial correlations*, and *Collinearity diagnostics*.

</div>

<div latex="true" class="task" id="Task">

(@) Test for outliers by looking at *casewise diagnostics*. This is also something that can be selected from the *Statistics* box, [@fig:mr2Stats].

</div>

![SPSS Linear Regression, Statistics](.11mr2/01-12-2016-45940.png "SPSS Linear Regression, Statistics"){#fig:mr2Stats}

<div latex="true" class="highlight" id="Remember">

An *outlier* is an extreme case of an individual who responded in a very different way compared with the rest of the sample. As multiple regression is sensitive to outliers, we may want to remove them and re-run the analysis without them. Extreme outliers can be easily identified using a statistic called Cook’s distance.

</div>

<div latex="true" class="task" id="Task">

(@) To ask SPSS to compute Cook's distance, return to the main Linear Regression dialogue [@fig:mr2Box]. There, click *Paste* to generate the syntax that will run the multiple regression. It should look like [@fig:regSyn].

</div>

![SPSS Syntax for Multiple Regression](.11mr2/01-12-2016-49359.png "SPSS Syntax for Multiple Regression"){#fig:regSyn}

<div latex="true" class="task" id="Task">

(@) Identify the line that reads: 

> /RESIDUALS DURBIN HIST(ZRESID) NORMPROB(ZRESID)

(@) Type *OUTLIERS(COOK)* after *‘NORMPROB(ZRESID)’* so that the line now looks like this:

> /RESIDUALS DURBIN HIST(ZRESID) NORMPROB(ZRESID) OUTLIERS(COOK)

- The Syntax window should now look like [@fig:regSynEdited].

</div>

![SPSS Syntax for Multiple Regression, Edited](.11mr2/01-12-2016-67156.png "SPSS Syntax for Multiple Regression, Edited"){#fig:regSynEdited}

You have now asked SPSS for Cook’s distance. This is a reliable way of identifying cases that could unduly influence your model.

<div latex="true" class="answer" id="Answer">

SPSS syntax for the above:

~~~

* Regression.
REGRESSION
  /DESCRIPTIVES MEAN STDDEV CORR SIG N
  /MISSING LISTWISE
  /STATISTICS COEFF OUTS CI(95) R ANOVA COLLIN TOL ZPP
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT tmbTotal
  /METHOD=ENTER consTotal worryTotal
  /SCATTERPLOT=(*ZRESID ,*ZPRED)
  /RESIDUALS DURBIN HISTOGRAM(ZRESID) NORMPROB(ZRESID) 
  OUTLIERS(COOK)
  /CASEWISE PLOT(ZRESID) OUTLIERS(3).

~~~

</div>

<div latex="true" class="task" id="Task">

(@) Go ahead and run the multiple regression. Do this by highlighting the syntax in the Syntax Window and clicking *Run selection* (if this isn't visible as part of the window itself, go to the menu *Run* > *Selection*).

</div>

## Step Five: Interpret the output

You've already interpreted a multiple regression in last week's session. Remember that the key things to look at are:

- The $R^2$ (and $R^2_{adj}$), which tells you how much variance in the outcome can be explained by the model. Find this in the *Model Summary*, [@fig:modelSummary].

- The *F* produced by the ANOVA, which tells you whether or not the model is reliable. Find this in the *ANOVA* table, [@fig:mr2ANOVA].

![SPSS Output---Model Summary](.11mr2/01-12-2016-34695.png "SPSS Output---Model Summary"){#fig:modelSummary}

![SPSS Output---ANOVA](.11mr2/01-12-2016-65515.png "SPSS Output---ANOVA"){#fig:mr2ANOVA}

- The *B* and *beta* coefficients, which provide information regarding the strength and direction of the relationship between each predictor and the outcome. See Figures [-@fig:coefLeft] and [-@fig:coefRight]. Use these to write the unstandardised or raw (@eq:UnstandardisedEquation) and standardised regression (@eq:StandardisedEquation) equations:

$$(DV_{pred})=b_0+(b_1 IV_1)+(b_2 IV_2)$$ {#eq:UnstandardisedEquation}

$$(ZDV_{pred})=(\beta_1 ZIV_1)+(\beta_2 ZIV_2)$$ {#eq:StandardisedEquation}

![SPSS Output---Coefficients, lefthand section](.11mr2/01-12-2016-14730.png "SPSS Output---Coefficients, lefthand section"){#fig:coefLeft}

![SPSS Output---Coefficients, righthand section](.11mr2/01-12-2016-30040.png "SPSS Output---Coefficients, righthand section"){#fig:coefRight}

- The *t* values, which tell us the predictors that predicted a significant amount of variance in the outcome variable.

- The *correlations*, which you can use to calculate the contributions of each predictor to the outcome. For instance, how much variance in the outcome did each individual predictor independently explain? Remember, because $r^2$ is shared variance (measured from 0 to 1), you need to square these values and multiply by 100 to get percentages of variance explained by each predictor.

<div latex="true" class="journal" id="Journal">

(@) Was the model significant? Report the appropriate statistics in APA style.

</div>

<div latex="true" class="answer" id="Answer">

- Yes, the model was significant. *F*(2,97) = 15.71, *MSE* = 262.13, *p* <.001

</div>

<div latex="true" class="journal" id="Journal">

(@) How much variance in the outcome variable did the model explain? Use the unadjusted and adjusted measures.

</div>

<div latex="true" class="answer" id="Answer">

- $R^2$ = .245 = 24.5%

- $R^2_{adj}$ = .229 = 22.9%

</div>

<div latex="true" class="journal" id="Journal">

(@) What are the unstandardised and standardised multiple regression equations?

</div>

<div latex="true" class="answer" id="Answer">

Unstandardised:

> $(timeManagement_{pred})=157.47-0.87(conscientiousness)-0.27(worry)$ 

Standardised:

> $(ZtimeManagement_{pred})=-0.47(Zconscientiousness)-0.18(Zworry)$

</div>

<div latex="true" class="journal" id="Journal">

(@) Were the individual predictors significant? How much unique variance did each of them explain? (Report appropriate statistics to justify your answer.)


</div>

<div latex="true" class="answer" id="Answer">

- Both predictors were significant individually, since both t-values (5.31, 2.00) were significant (*p* < .001, and *p* = .05).

- Conscientious predicted 22.09% ($(-0.47^2)*100$) unique variance in time management, whereas worry explained 3% ($(-0.18^2)*100$).

</div>

## Assumptions

You've performed the main analysis. Now let's look at the assumptions.

- Tolerance allows you assess problems of collinearity between your predictors. You find the statistics on the right hand side of the *Coefficients* table. See [@fig:coefRight]. Remember that tolerances below .10 are problematic.

- You can assess normality, linearity and homoscedasticity using the histograms (@fig:mr2Hist), P-P plot (@fig:mr2PP) and scatterplot (@fig:mr2Scatter).

![SPSS Output---Histogram of Frequency against Standarised Residuals](.11mr2/01-12-2016-93292.png "SPSS Output---Histogram of Frequency against Standarised Residuals"){#fig:mr2Hist}

![SPSS Output---Normal P-P Plot](.11mr2/01-12-2016-6407.png "SPSS Output---Normal P-P Plot"){#fig:mr2PP}

![SPSS Output---Scatterplot of Residuals against Predicted Values](.11mr2/01-12-2016-12114.png "SPSS Output---Scatterplot of Residuals against Predicted Values"){#fig:mr2Scatter}

- Residual statistics (@fig:mr2Resid) show us the range of the predicted values on the outcome measure. More importantly, it shows us the range of the residuals. Everyone in your sample has a residual that represents the difference between their actual score on the outcome measure and the predicted score based on the regression model. The larger these values, the worse your model is in predicting the outcome.

![SPSS Output---Residuals Statistics](.11mr2/01-12-2016-55930.png "SPSS Output---Residuals Statistics"){#fig:mr2Resid}

What we are really interested in, however, is if the model is bad in predicting anyone. In other words, does anyone have a very large residual? We've already requested *casewise diagnostics* (@fig:mr2Stats), so if anyone does have a very large residual, they should appear in a table like [@fig:mr2Casewise]. The Std. Residual in [@fig:mr2Resid] tells us the range (minimum and maximum) of the standard deviations of the residuals (i.e. the range of the standardized residuals). If the range falls within +/- 3 standard deviations, then we don’t have any outliers. (Note that the maximum for Std. Residual is 3.269, beyond the accepted range, indicating the presence of some large residuals.)

We can see this in [@fig:mr2Casewise], below, which identifies the outlying case (30). 

![SPSS Output---Casewise Diagnostics](.11mr2/01-12-2016-40689.png "SPSS Output---Casewise Diagnostics"){#fig:mr2Casewise}

But just because there is a large residual (error) associated with a case, that doesn't mean the case is influencing our regression unduly. To determine how much influence it has, we need to look at Cook's distance, which you'll see in [@fig:mr2Outliers].

![SPSS Output---Outlier Statistics](.11mr2/01-12-2016-18948.png "SPSS Output---Outlier Statistics"){#fig:mr2Outliers}

This table lists the top 10 cases, or, in other words, the 10 cases with the highest Cook’s Distance. If any of the cases listed are unduly influencing your results, their Cook’s distance will be greater than 1.00. If this is the case, you should consider carefully what to do (the case might need to be removed). Note the Cook's distance for case 30.

<div latex="true" class="journal" id="Journal">

(@) Bearing in mind the above tables, do the data contain outliers? Do you need to worry about them?

- Report the appropriate statistics to justify your answer.

</div>

<div latex="true" class="answer" id="Answer">

Yes, case 30 was an outlier because its standardised residual was greater than 3 standard deviations (3.27) from the mean residual (0, since this is a standard distribution). However, Cook’s distance for this case was .56, which is less than the recommend cut-off of 1, so we need not be unduly concerned with case 30.

</div>

<div latex="true" class="journal" id="Journal">

(@) Again, bearing in mind the above tables, do the data meet the assumptions of multiple regression? If not, why not? 

- Report the appropriate statistics to justify your answer.

</div>

<div latex="true" class="answer" id="Answer">

- Independence was met (Durbin-Watson was just over 2). See [@fig:modelSummary].

- Normality: Some deviation from normality, as shown in the Histogram (@fig:mr2Hist) and the Normal P-P plot (@fig:mr2PP).

- Linearity and homoscedasticity: The scatterplot between the standardised predicted outcome and standardised residuals show that there is no problem with linearity or homoscedasticity (@fig:mr2Scatter).

- Multicollinearity was not an issue since the Tolerance statistic is above .10 (@fig:coefRight).


</div>

<div latex="true" class="journal" id="Journal">

(@) Summarise the results of this regression.

</div>

<div latex="true" class="answer" id="Answer">

The model was significant (*F*(2,97) = 15.71, *MSE* = 262.13, *p* <.001) and it predicted 25% [23% if you prefer to use the adjusted $R^2$] of the variance in Time Management Behaviour (TBM). Both predictors were significant (both *p* values < .05) but conscientiousness was the most important predictor and it uniquely explained 22% of the variance in TBM, whereas worry only explained 3%. [If you wish, you can include the standardised and unstandardised models you provided in a previous answer.]

</div>


# Versions {#versions}

& deployments &

&& licence

&& referencesHeader
